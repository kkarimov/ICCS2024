{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import network and other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle, random, time\n",
    "from filelock import FileLock\n",
    "from src.Network import *\n",
    "from src.dataloader import RNA_Dataset\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define PATH for results for the playround experiment (with you own data). If you comment this code all the results with real data in 'results' folder will be updated and you want be able to test processing jupyter notes with real result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_RESULTS = './results_test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental settings are constrained by the following conditions:\n",
    "N_REPEATS * N_INITS <= NUM_GPUS / GPU_PER_RUN\n",
    "GPU_PER_RUN * memory of one GPU >= size of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_GPUS = 1 # number of GPU dedicated to training process\n",
    "N_REPEATS = 1 # number of repeats\n",
    "N_INITS = 1 # number of runs in parallel\n",
    "GPU_PER_RUN = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some settings for my particular dataloading flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "spleenDataFile = 'dataSpleen.csv'\n",
    "liverDataFile = 'dataLiver.csv'\n",
    "DATA_FILES = {'spleen': spleenDataFile, 'liver': liverDataFile}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set params of training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore, trainPerc = True, .85\n",
    "classTrain, AETrain, sparse = True, True, True\n",
    "latentDim, n_hidden = 128, 1024\n",
    "nEpochs = 20000\n",
    "learningRateAE, learningRateD, weightDecay = .0001, .0001, .01\n",
    "alpha, beta, gamma, lambd = 10.0, 1.0, 0.0001, 0.0001\n",
    "use_cuda = torch.cuda.is_available()\n",
    "shuffleTrain = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define trainer for specific dataset and experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(DATA_NAME, EXPERIMENT, shuffleTrain):\n",
    "    \n",
    "    PATH = PATH_DATA + DATA_NAME\n",
    "    if len(EXPERIMENT) >1:\n",
    "        rootDir = PATH_RESULTS + DATA_NAME + 'all/'\n",
    "    else:\n",
    "        rootDir = PATH_RESULTS + DATA_NAME + EXPERIMENT[0] + '/'\n",
    "    os.makedirs(rootDir + 'losses/', exist_ok=True)\n",
    "\n",
    "    if os.path.exists(rootDir + 'losses/' + \"losses.pickle\"):\n",
    "        try:\n",
    "            os.remove(rootDir + 'losses/' + \"losses.pickle\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error: {e.strerror}\")\n",
    "            pass\n",
    "\n",
    "    if os.path.exists(rootDir + \"model.pth\"):\n",
    "        try:\n",
    "            os.remove(rootDir + \"model.pth\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error: {e.strerror}\")\n",
    "            pass\n",
    "\n",
    "    print(f\"\"\"\n",
    "Starting one run experiment {EXPERIMENT} with the dataset {DATA_NAME}\n",
    "          \"\"\")\n",
    "\n",
    "    start = time.time()\n",
    "    seed = random.randrange(1, 1000)\n",
    "    dataset = RNA_Dataset(PATH, DATA_FILES, EXPERIMENT, zscore, trainPerc, seed)\n",
    "    inputDim = len(dataset.features)\n",
    "    \n",
    "    Train, Valid = dict(), dict()\n",
    "    shuffleValid = False #for visualization shuffleTrain = False\n",
    "    for _ in EXPERIMENT:\n",
    "        TrainTemp, ValidTemp = dataset._download(_, shuffleTrain, shuffleValid)\n",
    "        Train[_] = TrainTemp\n",
    "        Valid[_] = ValidTemp\n",
    "\n",
    "    network = Network(EXPERIMENT, use_cuda,\n",
    "            inputDim, latentDim, n_hidden, learningRateAE, learningRateD, weightDecay, alpha, beta, lambd, gamma, \n",
    "            classTrain, AETrain, sparse)\n",
    "    Losses = network.trainLoop(Train, Valid, nEpochs)\n",
    "\n",
    "    # save model for further inference (show latents distribution)\n",
    "    torch.save(network, rootDir + 'model.pth')\n",
    "\n",
    "    # Save losses (comment if already trained and start from loading and plot losses)\n",
    "    with open(rootDir + 'losses/'+f'losses.pickle', 'wb') as handle:\n",
    "            pickle.dump(Losses, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print(f\"Training for the experiment {EXPERIMENT} with the  dataset {DATA_NAME} took {time.time()-start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick dataset and experiment for one run of training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting one run experiment ['spleen', 'liver'] with the dataset 1_[res]_[sus, delayedSus]/\n",
      "          \n",
      "Training for the experiment ['spleen', 'liver'] with the  dataset 1_[res]_[sus, delayedSus]/ took 683.873119354248 seconds\n"
     ]
    }
   ],
   "source": [
    "DATA_NAME, EXPERIMENT = '1_[res]_[sus, delayedSus]/', ['spleen', 'liver']\n",
    "trainer(DATA_NAME, EXPERIMENT, shuffleTrain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('iccs2024')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0ffa3a6cb32ce44b6481723c229ec4efbb1134d3cba26699f561700e30b9254"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
