{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import network and other stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, joblib, pickle, random, time\n",
    "from filelock import FileLock\n",
    "from src.Network import *\n",
    "from src.dataloader import RNA_Dataset\n",
    "import ray\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define PATH for results for the playround experiment (with you own data). If you comment this code all the results with real data in 'results' folder will be updated and you want be able to test processing jupyter notes with real result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PATH_RESULTS = './results_test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define relative paths for datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_NAMES = ['1_[res]_[sus, delayedSus]/', '1_[tol]_[sus, delayedSus]/', '[un]_[1]/']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define names of experiments (multi-domain, domain1, domain2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENTS = [['spleen', 'liver'], ['spleen'], ['liver']] # i.e. multi-domain, domain1, domain2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimental settings are constrained by the following conditions:\n",
    "N_REPEATS * N_INITS <= NUM_GPUS / GPU_PER_RUN\n",
    "GPU_PER_RUN * memory of one GPU >= size of network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_GPUS = 2 # number of GPU dedicated to training process\n",
    "N_REPEATS = 2 # number of repeats\n",
    "N_INITS = 10 # number of runs in parallel\n",
    "GPU_PER_RUN = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some settings for my particular dataloading flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spleenDataFile = 'dataSpleen.csv'\n",
    "liverDataFile = 'dataLiver.csv'\n",
    "DATA_FILES = {'spleen': spleenDataFile, 'liver': liverDataFile}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set params of training network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore, trainPerc = True, .85\n",
    "classTrain, AETrain, sparse = True, True, True\n",
    "latentDim, n_hidden = 128, 1024\n",
    "nEpochs = 20000\n",
    "learningRateAE, learningRateD, weightDecay = .0001, .0001, .01\n",
    "alpha, beta, gamma, lambd = 10.0, 1.0, 0.0001, 0.0001\n",
    "use_cuda = torch.cuda.is_available()\n",
    "shuffleTrain = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define trainer for specific dataset and experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(DATA_NAME, EXPERIMENT, shuffleTrain):\n",
    "    \n",
    "    PATH = PATH_DATA + DATA_NAME\n",
    "    if len(EXPERIMENT) >1:\n",
    "        rootDir = PATH_RESULTS + DATA_NAME + 'all/'\n",
    "    else:\n",
    "        rootDir = PATH_RESULTS + DATA_NAME + EXPERIMENT[0] + '/'\n",
    "    os.makedirs(rootDir, exist_ok=True)\n",
    "\n",
    "    if os.path.exists(rootDir + \"weightsList.pickle\"):\n",
    "        try:\n",
    "            os.remove(rootDir + \"weightsList.pickle\")\n",
    "            os.remove(rootDir + \"weightsList.pickle.lock\")\n",
    "        except OSError as e:\n",
    "            print(f\"Error: {e.strerror}\")\n",
    "            pass\n",
    "\n",
    "    ray.init(num_gpus=NUM_GPUS)\n",
    "\n",
    "    print(f\"\"\"\n",
    "Starting {EXPERIMENT} experiment with the dataset {DATA_NAME} and the following setup:\n",
    "    N_REPEATS: {N_REPEATS}\n",
    "    N_INITS: {N_INITS}\n",
    "    nEpochs: {nEpochs}\n",
    "          \"\"\")\n",
    "\n",
    "    start = time.time()\n",
    "    for iter in range(N_REPEATS):\n",
    "\n",
    "        seed = random.randrange(1, 1000)\n",
    "        dataset = RNA_Dataset(PATH, DATA_FILES, EXPERIMENT, zscore, trainPerc, seed)\n",
    "        inputDim = len(dataset.features)\n",
    "        \n",
    "        Train, Valid = dict(), dict()\n",
    "        shuffleValid = False #for visualization shuffleTrain = False\n",
    "        for _ in EXPERIMENT:\n",
    "            TrainTemp, ValidTemp = dataset._download(_, shuffleTrain, shuffleValid)\n",
    "            Train[_] = TrainTemp\n",
    "            Valid[_] = ValidTemp\n",
    "        Train = ray.put(Train)\n",
    "        Valid = ray.put(Valid)\n",
    "\n",
    "        RemoteNetwork = ray.remote(num_gpus=GPU_PER_RUN)(Network)\n",
    "        Actors = {}\n",
    "        for _ in range(N_INITS):\n",
    "            Actors['Actor: {}'.format(_)] = RemoteNetwork.remote(EXPERIMENT, use_cuda,\n",
    "                inputDim, latentDim, n_hidden, learningRateAE, learningRateD, weightDecay, alpha, beta, lambd, gamma, \n",
    "                classTrain, AETrain, sparse)\n",
    "        ray.get([value.trainLoop.remote(Train, Valid, nEpochs) for value in Actors.values()])\n",
    "        weights = ray.get([value.getWeightsSparse.remote() for value in Actors.values()])\n",
    "        weightsSparse = [_ for _ in weights]\n",
    "\n",
    "        with FileLock(rootDir + \"weightsList.pickle.lock\"):\n",
    "            if os.path.isfile(rootDir + \"weightsList.pickle\"):\n",
    "                    listOld = pickle.load( open(rootDir + \"weightsList.pickle\", \"rb\" ) )\n",
    "                    listOld.extend(weightsSparse)\n",
    "                    pickle.dump( listOld, open( rootDir + \"weightsList.pickle\", \"wb\" ) )\n",
    "            else:\n",
    "                pickle.dump(weightsSparse, open(rootDir + \"weightsList.pickle\", \"wb\" ) )\n",
    "    ray.shutdown()\n",
    "    print(f\"Training for the experiment {EXPERIMENT} with the  dataset {DATA_NAME} took {time.time()-start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run all both multi-domain and two one domain trainings for one dataset '1_[res]_[sus, delayedSus]', i.e. 'resistant' versus 'susceptible'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 03:32:10,201\tINFO worker.py:1518 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting ['spleen', 'liver'] experiment with the dataset 1_[res]_[sus, delayedSus]/ and the following setup:\n",
      "    N_REPEATS: 2\n",
      "    N_INITS: 10\n",
      "    nEpochs: 20000\n",
      "          \n",
      "Training for the experiment ['spleen', 'liver'] with the  dataset 1_[res]_[sus, delayedSus]/ took 4191.774039983749 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 04:42:04,608\tINFO worker.py:1518 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting ['spleen'] experiment with the dataset 1_[res]_[sus, delayedSus]/ and the following setup:\n",
      "    N_REPEATS: 2\n",
      "    N_INITS: 10\n",
      "    nEpochs: 20000\n",
      "          \n",
      "Training for the experiment ['spleen'] with the  dataset 1_[res]_[sus, delayedSus]/ took 2398.7983787059784 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-17 05:22:07,267\tINFO worker.py:1518 -- Started a local Ray instance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting ['liver'] experiment with the dataset 1_[res]_[sus, delayedSus]/ and the following setup:\n",
      "    N_REPEATS: 2\n",
      "    N_INITS: 10\n",
      "    nEpochs: 20000\n",
      "          \n",
      "Training for the experiment ['liver'] with the  dataset 1_[res]_[sus, delayedSus]/ took 1927.613466501236 seconds\n"
     ]
    }
   ],
   "source": [
    "DATA_NAME = '1_[res]_[sus, delayedSus]/'\n",
    "for EXPERIMENT in EXPERIMENTS:\n",
    "    trainer(DATA_NAME, EXPERIMENT, shuffleTrain)\n",
    "\n",
    "# # to run all datasets:\n",
    "# for DATA_NAME in DATA_NAMES:\n",
    "#     for EXPERIMENT in EXPERIMENTS:\n",
    "#         trainer(DATA_NAME, EXPERIMENT, shuffleTrain)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('iccs2024')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0ffa3a6cb32ce44b6481723c229ec4efbb1134d3cba26699f561700e30b9254"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
